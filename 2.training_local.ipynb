{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modlue 2. Training with CutMix\n",
    "---\n",
    "\n",
    "본 모듈에서는 Amzaon SageMaker API 호출 없이 PyTorch 프레임워크 자체 구현만으로 모델 훈련을 수행해 봅니다. PyTorch의 문법 및 용법에 익숙하신 분들은 이 모듈을 건너 뛰고 Module 3으로 곧바로 진행하셔도 됩니다.\n",
    "\n",
    "훈련을 원활하게 수행하시려면 GPU가 장착된 SageMaker notebook instance를 사용하셔야 합니다. (예: `g4dn.xlarge, p2.xlarge, p3.2xlarge`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import time, datetime\n",
    "import gc, glob2\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch, albumentations를 최신 버전으로 업데이트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U fastai torch albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Splits Data\n",
    "\n",
    "Metric 평가를 위해, 훈련 데이터셋/검증 데이터셋을 분리합니다. 본 핸즈온에서는 훈련 데이터셋을 5-fold로 분리 후 4번째 fold를 검증 데이터셋으로 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./input/train_folds.csv')\n",
    "\n",
    "num_folds = 5\n",
    "vld_fold_idx = 4\n",
    "trn_fold = [i for i in range(num_folds) if i not in [vld_fold_idx]]\n",
    "vld_fold = [vld_fold_idx]\n",
    "\n",
    "trn_idx = train_df.loc[train_df['fold'].isin(trn_fold)].index\n",
    "vld_idx = train_df.loc[train_df['fold'].isin(vld_fold)].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Transformation w/ Augmentation\n",
    "\n",
    "본 핸즈온에서는 `albumentations` 패키지를 사용하여 Data augmentation을 수행합니다. 물론 `torchvision.transforms`에서도 이미 augmentation을 지원하고 있지만, 더 많은 augmentation 기법들을 지원하고 있으며 수행 속도 또한 훨씬 빠릅니다.\n",
    "관련 내용은 아래 URL을 참조해 주세요.\n",
    "\n",
    "- [Albumentations: fast and flexible image augmentations](https://arxiv.org/pdf/1809.06839.pdf)\n",
    "- [migrating_from_torchvision_to_albumentations.ipynb](https://github.com/albumentations-team/albumentations_examples/blob/master/notebooks/migrating_from_torchvision_to_albumentations.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    Rotate,HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, RandomBrightnessContrast, IAAPiecewiseAffine,\n",
    "    IAASharpen, IAAEmboss, Flip, OneOf, Compose\n",
    ")\n",
    "from albumentations.pytorch import ToTensor, ToTensorV2\n",
    "\n",
    "train_transforms = Compose([\n",
    "    Rotate(20),\n",
    "        OneOf([\n",
    "            IAAAdditiveGaussianNoise(),\n",
    "            GaussNoise(),\n",
    "        ], p=0.2),\n",
    "        OneOf([\n",
    "            MotionBlur(p=.2),\n",
    "            MedianBlur(blur_limit=3, p=0.1),\n",
    "            Blur(blur_limit=3, p=0.1),\n",
    "        ], p=0.2),\n",
    "        ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),\n",
    "        OneOf([\n",
    "            OpticalDistortion(p=0.3),\n",
    "            GridDistortion(p=.1),\n",
    "            IAAPiecewiseAffine(p=0.3),\n",
    "        ], p=0.2),\n",
    "        OneOf([\n",
    "            CLAHE(clip_limit=2),\n",
    "            IAASharpen(),\n",
    "            IAAEmboss(),\n",
    "            RandomBrightnessContrast(),            \n",
    "        ], p=0.3),\n",
    "        HueSaturationValue(p=0.3),\n",
    "    ToTensor()\n",
    "    ], p=1.0)\n",
    "\n",
    "\n",
    "valid_transforms = Compose([\n",
    "    ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make DataLoader\n",
    "PyTorch는 미니배치를 쉽게 로딩할 수 있는 `torch.utils.data.Dataset`과 `torch.utils.data.DataLoader`를 제공하며, 이를 사용하여\n",
    "미니배치 셔플링(shuffling), 병렬 처리를 쉽게 구현할 수 있습니다.\n",
    "\n",
    "또한, `torch.utils.data.Dataset`을 상속받아 사용자 정의 Dataset을 아래와 같이 쉽게 구성할 수 있습니다.<br>\n",
    "사용자 정의 Dataset 구현의 기본적인 뼈대는 데이터셋 초기화에 필요한 `__init__(self)` 메서드, 데이터셋의 총 샘플 수를 리턴해 주는 `__len__(self)` 메서드, 특정 1개의 샘플을 가져오는 `__getitem__(self, index)` 메서드의 구현입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Images\n",
    "parquet 파일을 로딩하여 dataframe로 저장한 후, numpy array로 변환하여 전체 데이터셋을 메모리에 저장합니다.\n",
    "본 핸즈온은 데이터셋 크기가 크지 않아 전체 이미지 데이터를 메모리에 올렸지만, 수백만장 이상의 대용량 데이터 사용 시에는 데이터셋을 TFRecord, RecordIO와 같은 직렬 파일로 인코딩하여 저장하거나 각 이미지를 pickle로 저장해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.1 s, sys: 18.8 s, total: 45.9 s\n",
      "Wall time: 18.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def get_images(data_dir='input', data_type='train'):\n",
    "    files = sorted(glob2.glob(f'{data_dir}/{data_type}_*.feather'))\n",
    "\n",
    "    image_df_list = [pd.read_feather(f) for f in files]\n",
    "    images = [df.iloc[:, 1:].values.reshape(-1, HEIGHT, WIDTH) for df in image_df_list]\n",
    "    del image_df_list\n",
    "    gc.collect()\n",
    "    images = np.concatenate(images, axis=0)\n",
    "    return images\n",
    "\n",
    "imgs = get_images(data_type='train')\n",
    "test_imgs = get_images(data_type='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 데이터를 `jpg` 파일로 변환하여 저장합니다. 이 파일들은 모델 배포 시 테스트 이미지로 활용하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = os.path.join(os.getcwd(), 'test_imgs')\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "for idx, img_arr in enumerate(test_imgs):\n",
    "    img = Image.fromarray(test_imgs[idx])\n",
    "    img.save(f'test_imgs/test_{idx}.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset 클래스 정의\n",
    "`__getitem__(self, idx)`을 통해 데이터셋 전체를 메모리에 올리지 않고 특정 샘플이 필요할 때에만 불러와서 읽습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BangaliDataset(Dataset):\n",
    "    def __init__(self, imgs, label_df=None, transform=None):\n",
    "        self.imgs = imgs\n",
    "        self.label_df = label_df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_idx = self.label_df.iloc[idx].id\n",
    "        img = (self.imgs[img_idx]).astype(np.uint8)\n",
    "        img = 255 - img\n",
    "    \n",
    "        img = img[:,:,np.newaxis]\n",
    "        img = np.repeat(img, 3, axis=2)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(image=img)['image']        \n",
    "        \n",
    "        if self.label_df is not None:\n",
    "            label_1 = self.label_df.iloc[idx].grapheme_root\n",
    "            label_2 = self.label_df.iloc[idx].vowel_diacritic\n",
    "            label_3 = self.label_df.iloc[idx].consonant_diacritic           \n",
    "            return img, np.array([label_1, label_2, label_3])        \n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "trn_dataset = BangaliDataset(imgs=imgs, label_df=train_df.loc[trn_idx], transform=train_transforms)\n",
    "vld_dataset = BangaliDataset(imgs=imgs, label_df=train_df.loc[vld_idx], transform=valid_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1194111a58>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.randint(len(trn_idx))\n",
    "img_sample = trn_dataset[idx][0].permute(1, 2, 0).numpy().squeeze()\n",
    "plt.imshow(img_sample, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_loader = DataLoader(trn_dataset, shuffle=True, num_workers=4, batch_size=BATCH_SIZE)\n",
    "vld_loader = DataLoader(vld_dataset, shuffle=False, num_workers=4, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make model, optimizer, and criterion for Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 파라메터들을 random 분포로 초기화화여 훈련하는 것보다 이미 ImageNet 데이터로 pre-trained되어 있는 모델 파라메터를 사용하는 것이 더 효율적으로 훈련을 수행하는 방법입니다. \n",
    "어떤 모델을 사용해도 무방하지만, 본 핸즈온에서는 비교적 간단한 모델인 ResNet-18을 사용하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /home/ec2-user/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a32d3ef227684e1ebc5559cbd354c923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, models\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "last_hidden_units = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(last_hidden_units, 186)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max',\n",
    "                                                      verbose=True, patience=5, \n",
    "                                                      factor=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training\n",
    "`p3.2xlarge` 노트북 인스턴스 기준으로 epoch당 5분 30초~5분 40초 정도 소요됩니다. 원활한 핸즈온을 위해 본 section은 건너뛰어도 되며, 이미 훈련이 완료된 모델을 그대로 사용하시면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 10/628] loss: 3.2737\n",
      "[Epoch 0 Batch 20/628] loss: 2.9395\n",
      "[Epoch 0 Batch 30/628] loss: 2.5623\n",
      "[Epoch 0 Batch 40/628] loss: 2.5006\n",
      "[Epoch 0 Batch 50/628] loss: 2.3222\n",
      "[Epoch 0 Batch 60/628] loss: 2.2254\n",
      "[Epoch 0 Batch 70/628] loss: 1.5951\n",
      "[Epoch 0 Batch 80/628] loss: 1.8569\n",
      "[Epoch 0 Batch 90/628] loss: 1.9710\n",
      "[Epoch 0 Batch 100/628] loss: 2.0559\n",
      "[Epoch 0 Batch 110/628] loss: 1.7522\n",
      "[Epoch 0 Batch 120/628] loss: 1.9535\n",
      "[Epoch 0 Batch 130/628] loss: 1.7990\n",
      "[Epoch 0 Batch 140/628] loss: 1.6283\n",
      "[Epoch 0 Batch 150/628] loss: 1.8619\n",
      "[Epoch 0 Batch 160/628] loss: 1.6574\n",
      "[Epoch 0 Batch 170/628] loss: 1.5432\n",
      "[Epoch 0 Batch 180/628] loss: 1.6980\n",
      "[Epoch 0 Batch 190/628] loss: 1.6882\n",
      "[Epoch 0 Batch 200/628] loss: 1.5007\n",
      "[Epoch 0 Batch 210/628] loss: 1.9398\n",
      "[Epoch 0 Batch 220/628] loss: 1.3813\n",
      "[Epoch 0 Batch 230/628] loss: 1.4822\n",
      "[Epoch 0 Batch 240/628] loss: 1.6666\n",
      "[Epoch 0 Batch 250/628] loss: 1.4196\n",
      "[Epoch 0 Batch 260/628] loss: 1.6154\n",
      "[Epoch 0 Batch 270/628] loss: 1.5492\n",
      "[Epoch 0 Batch 280/628] loss: 1.7420\n",
      "[Epoch 0 Batch 290/628] loss: 1.5228\n",
      "[Epoch 0 Batch 300/628] loss: 1.6921\n",
      "[Epoch 0 Batch 310/628] loss: 1.6546\n",
      "[Epoch 0 Batch 320/628] loss: 1.0239\n",
      "[Epoch 0 Batch 330/628] loss: 1.9390\n",
      "[Epoch 0 Batch 340/628] loss: 1.5049\n",
      "[Epoch 0 Batch 350/628] loss: 1.3431\n",
      "[Epoch 0 Batch 360/628] loss: 1.6732\n",
      "[Epoch 0 Batch 370/628] loss: 1.4140\n",
      "[Epoch 0 Batch 380/628] loss: 1.5213\n",
      "[Epoch 0 Batch 390/628] loss: 1.8106\n",
      "[Epoch 0 Batch 400/628] loss: 1.3734\n",
      "[Epoch 0 Batch 410/628] loss: 1.3371\n",
      "[Epoch 0 Batch 420/628] loss: 1.4043\n",
      "[Epoch 0 Batch 430/628] loss: 1.6400\n",
      "[Epoch 0 Batch 440/628] loss: 1.1451\n",
      "[Epoch 0 Batch 450/628] loss: 0.8172\n",
      "[Epoch 0 Batch 460/628] loss: 1.1898\n",
      "[Epoch 0 Batch 470/628] loss: 0.9204\n",
      "[Epoch 0 Batch 480/628] loss: 0.8296\n",
      "[Epoch 0 Batch 490/628] loss: 0.7586\n",
      "[Epoch 0 Batch 500/628] loss: 1.7847\n",
      "[Epoch 0 Batch 510/628] loss: 1.1478\n",
      "[Epoch 0 Batch 520/628] loss: 1.5837\n",
      "[Epoch 0 Batch 530/628] loss: 1.9223\n",
      "[Epoch 0 Batch 540/628] loss: 1.4117\n",
      "[Epoch 0 Batch 550/628] loss: 1.6838\n",
      "[Epoch 0 Batch 560/628] loss: 1.5532\n",
      "[Epoch 0 Batch 570/628] loss: 1.1367\n",
      "[Epoch 0 Batch 580/628] loss: 1.3179\n",
      "[Epoch 0 Batch 590/628] loss: 0.8900\n",
      "[Epoch 0 Batch 600/628] loss: 0.6942\n",
      "[Epoch 0 Batch 610/628] loss: 0.8620\n",
      "[Epoch 0 Batch 620/628] loss: 1.6903\n",
      "== Start Validation ==\n",
      "[Epoch 0] trn_loss: 1.5924, vld_loss: 1.2437, score: 0.8805, score_each: [0.8568, 0.9107, 0.8978]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    '''\n",
    "    CutMix Helper function.\n",
    "    Retrieved from https://github.com/clovaai/CutMix-PyTorch/blob/master/train.py\n",
    "    '''\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    # 폭과 높이는 주어진 이미지의 폭과 높이의 beta distribution에서 뽑은 lambda로 얻는다\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    \n",
    "    # patch size 의 w, h 는 original image 의 w,h 에 np.sqrt(1-lambda) 를 곱해준 값입니다.\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # patch의 중심점은 uniform하게 뽑힘\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "best_score = -1\n",
    "log_interval = 10\n",
    "training_stats = []\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch_id in range(num_epochs):\n",
    "\n",
    "    ################################################################################\n",
    "    # ==> Training phase\n",
    "    ################################################################################    \n",
    "    trn_loss = []\n",
    "    model.train()\n",
    "    \n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_id, (inputs, targets) in enumerate((trn_loader)):\n",
    "        inputs = inputs.cuda()\n",
    "        targets = targets.cuda()\n",
    "        targets_gra = targets[:, 0]\n",
    "        targets_vow = targets[:, 1]\n",
    "        targets_con = targets[:, 2]\n",
    "                    \n",
    "        # 50%의 확률로 원본 데이터 그대로 사용    \n",
    "        if np.random.rand() < 0.5:\n",
    "            logits = model(inputs)\n",
    "            grapheme = logits[:, :168]\n",
    "            vowel = logits[:, 168:179]\n",
    "            cons = logits[:, 179:]\n",
    "            \n",
    "            loss1 = loss_fn(grapheme, targets_gra)\n",
    "            loss2 = loss_fn(vowel, targets_vow)\n",
    "            loss3 = loss_fn(cons, targets_con) \n",
    "        \n",
    "        else:\n",
    "            \n",
    "            lam = np.random.beta(1.0, 1.0) \n",
    "            rand_index = torch.randperm(inputs.size()[0])\n",
    "            shuffled_targets_gra = targets_gra[rand_index]\n",
    "            shuffled_targets_vow = targets_vow[rand_index]\n",
    "            shuffled_targets_con = targets_con[rand_index]\n",
    "            \n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)\n",
    "            inputs[:, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "            # 픽셀 비율과 정확히 일치하도록 lambda 파라메터 조정  \n",
    "            lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (inputs.size()[-1] * inputs.size()[-2]))\n",
    "            \n",
    "            logits = model(inputs)\n",
    "            grapheme = logits[:,:168]\n",
    "            vowel = logits[:, 168:179]\n",
    "            cons = logits[:, 179:]\n",
    "            \n",
    "            loss1 = loss_fn(grapheme, targets_gra) * lam + loss_fn(grapheme, shuffled_targets_gra) * (1. - lam)\n",
    "            loss2 = loss_fn(vowel, targets_vow) * lam + loss_fn(vowel, shuffled_targets_vow) * (1. - lam)\n",
    "            loss3 = loss_fn(cons, targets_con) * lam + loss_fn(cons, shuffled_targets_con) * (1. - lam)\n",
    "        \n",
    "        loss = 0.5 * loss1 + 0.25 * loss2 + 0.25 * loss3    \n",
    "        trn_loss.append(loss.item())\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Printing vital information\n",
    "        if (batch_id + 1) % (log_interval) == 0:\n",
    "            s = f'[Epoch {epoch_id} Batch {batch_id+1}/{len(trn_loader)}] ' \\\n",
    "            f'loss: {running_loss / log_interval:.4f}'\n",
    "            print(s)\n",
    "            running_loss = 0\n",
    "\n",
    "    # Measure how long this epoch took.\n",
    "    trn_time = format_time(time.time() - t0)        \n",
    "\n",
    "    ################################################################################\n",
    "    # ==> Validation phase\n",
    "    ################################################################################\n",
    "    val_loss = []\n",
    "    val_true = []\n",
    "    val_pred = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in vld_loader:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            logits = model(inputs)\n",
    "            grapheme = logits[:,:168]\n",
    "            vowel = logits[:, 168:179]\n",
    "            cons = logits[:, 179:]\n",
    "\n",
    "            loss= 0.5* loss_fn(grapheme, targets[:,0]) + 0.25*loss_fn(vowel, targets[:,1]) + \\\n",
    "            0.25*loss_fn(vowel, targets[:,2])\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "\n",
    "            grapheme = grapheme.cpu().argmax(dim=1).data.numpy()\n",
    "            vowel = vowel.cpu().argmax(dim=1).data.numpy()\n",
    "            cons = cons.cpu().argmax(dim=1).data.numpy()\n",
    "\n",
    "            val_true.append(targets.cpu().numpy())\n",
    "            val_pred.append(np.stack([grapheme, vowel, cons], axis=1))                \n",
    "\n",
    "    val_true = np.concatenate(val_true)\n",
    "    val_pred = np.concatenate(val_pred)\n",
    "    val_loss = np.mean(val_loss)\n",
    "    trn_loss = np.mean(trn_loss)\n",
    "\n",
    "    score_g = recall_score(val_true[:,0], val_pred[:,0], average='macro')\n",
    "    score_v = recall_score(val_true[:,1], val_pred[:,1], average='macro')\n",
    "    score_c = recall_score(val_true[:,2], val_pred[:,2], average='macro')\n",
    "    final_score = np.average([score_g, score_v, score_c], weights=[2,1,1])\n",
    "   \n",
    "    # Printing vital information\n",
    "    print('== Start Validation ==')\n",
    "    s = f'[Epoch {epoch_id}] ' \\\n",
    "    f'trn_loss: {trn_loss:.4f}, vld_loss: {val_loss:.4f}, score: {final_score:.4f}, ' \\\n",
    "    f'score_each: [{score_g:.4f}, {score_v:.4f}, {score_c:.4f}]'          \n",
    "    print(s)\n",
    "\n",
    "    ################################################################################\n",
    "    # ==> Save checkpoint and training stats\n",
    "    ################################################################################        \n",
    "    if final_score > best_score:\n",
    "        best_score = final_score\n",
    "        state_dict = model.cpu().state_dict()\n",
    "        model = model.cuda()\n",
    "        torch.save(state_dict, 'model.pt')\n",
    "        \n",
    "    # Record all statistics from this epoch\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_id + 1,\n",
    "            'trn_loss': trn_loss,\n",
    "            'trn_time': trn_time,            \n",
    "            'val_loss': val_loss,\n",
    "            'score': final_score,\n",
    "            'score_g': score_g,\n",
    "            'score_v': score_v,\n",
    "            'score_c': score_c            \n",
    "        }\n",
    "    )            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 10/628] loss: 3.1508\n",
      "[Epoch 0 Batch 20/628] loss: 2.7415\n",
      "[Epoch 0 Batch 30/628] loss: 2.6588\n",
      "[Epoch 0 Batch 40/628] loss: 2.2074\n",
      "[Epoch 0 Batch 50/628] loss: 2.4823\n",
      "[Epoch 0 Batch 60/628] loss: 2.2221\n",
      "[Epoch 0 Batch 70/628] loss: 1.8909\n",
      "[Epoch 0 Batch 80/628] loss: 1.6422\n",
      "[Epoch 0 Batch 90/628] loss: 2.2726\n",
      "[Epoch 0 Batch 100/628] loss: 1.4553\n",
      "[Epoch 0 Batch 110/628] loss: 1.6459\n",
      "[Epoch 0 Batch 120/628] loss: 1.9580\n",
      "[Epoch 0 Batch 130/628] loss: 1.5981\n",
      "[Epoch 0 Batch 140/628] loss: 1.8985\n",
      "[Epoch 0 Batch 150/628] loss: 1.7036\n",
      "[Epoch 0 Batch 160/628] loss: 1.5649\n",
      "[Epoch 0 Batch 170/628] loss: 1.7639\n",
      "[Epoch 0 Batch 180/628] loss: 1.4936\n",
      "[Epoch 0 Batch 190/628] loss: 1.1015\n",
      "[Epoch 0 Batch 200/628] loss: 2.0834\n",
      "[Epoch 0 Batch 210/628] loss: 1.8302\n",
      "[Epoch 0 Batch 220/628] loss: 1.2091\n",
      "[Epoch 0 Batch 230/628] loss: 1.5838\n",
      "[Epoch 0 Batch 240/628] loss: 1.4027\n",
      "[Epoch 0 Batch 250/628] loss: 1.5748\n",
      "[Epoch 0 Batch 260/628] loss: 1.2333\n",
      "[Epoch 0 Batch 270/628] loss: 1.5405\n",
      "[Epoch 0 Batch 280/628] loss: 1.0223\n",
      "[Epoch 0 Batch 290/628] loss: 1.5216\n",
      "[Epoch 0 Batch 300/628] loss: 1.2704\n",
      "[Epoch 0 Batch 310/628] loss: 1.7270\n",
      "[Epoch 0 Batch 320/628] loss: 1.4181\n",
      "[Epoch 0 Batch 330/628] loss: 0.7801\n",
      "[Epoch 0 Batch 340/628] loss: 1.9166\n",
      "[Epoch 0 Batch 350/628] loss: 1.7332\n",
      "[Epoch 0 Batch 360/628] loss: 1.4336\n",
      "[Epoch 0 Batch 370/628] loss: 1.6455\n",
      "[Epoch 0 Batch 380/628] loss: 2.1148\n",
      "[Epoch 0 Batch 390/628] loss: 0.8678\n",
      "[Epoch 0 Batch 400/628] loss: 0.9205\n",
      "[Epoch 0 Batch 410/628] loss: 1.3361\n",
      "[Epoch 0 Batch 420/628] loss: 0.8298\n",
      "[Epoch 0 Batch 430/628] loss: 1.4895\n",
      "[Epoch 0 Batch 440/628] loss: 1.6704\n",
      "[Epoch 0 Batch 450/628] loss: 1.0054\n",
      "[Epoch 0 Batch 460/628] loss: 1.0254\n",
      "[Epoch 0 Batch 470/628] loss: 1.3762\n",
      "[Epoch 0 Batch 480/628] loss: 1.4398\n",
      "[Epoch 0 Batch 490/628] loss: 1.6620\n",
      "[Epoch 0 Batch 500/628] loss: 1.1178\n",
      "[Epoch 0 Batch 510/628] loss: 0.8277\n",
      "[Epoch 0 Batch 520/628] loss: 1.2201\n",
      "[Epoch 0 Batch 530/628] loss: 1.3103\n",
      "[Epoch 0 Batch 540/628] loss: 1.5474\n",
      "[Epoch 0 Batch 550/628] loss: 1.3435\n",
      "[Epoch 0 Batch 560/628] loss: 1.0034\n",
      "[Epoch 0 Batch 570/628] loss: 1.3102\n",
      "[Epoch 0 Batch 580/628] loss: 1.3117\n",
      "[Epoch 0 Batch 590/628] loss: 1.2184\n",
      "[Epoch 0 Batch 600/628] loss: 1.5493\n",
      "[Epoch 0 Batch 610/628] loss: 1.9158\n",
      "[Epoch 0 Batch 620/628] loss: 0.8644\n",
      "== Start Validation ==\n",
      "[Epoch 0] trn_loss: 1.5552, vld_loss: 1.3846, score: 0.8557, score_each: [0.8070, 0.9268, 0.8818]\n",
      "[Epoch 1 Batch 10/628] loss: 1.7388\n",
      "[Epoch 1 Batch 20/628] loss: 1.0611\n",
      "[Epoch 1 Batch 30/628] loss: 0.9283\n",
      "[Epoch 1 Batch 40/628] loss: 1.5120\n",
      "[Epoch 1 Batch 50/628] loss: 1.6737\n",
      "[Epoch 1 Batch 60/628] loss: 1.8157\n",
      "[Epoch 1 Batch 70/628] loss: 1.3749\n",
      "[Epoch 1 Batch 80/628] loss: 0.6684\n",
      "[Epoch 1 Batch 90/628] loss: 1.0144\n",
      "[Epoch 1 Batch 100/628] loss: 1.1125\n",
      "[Epoch 1 Batch 110/628] loss: 0.8450\n",
      "[Epoch 1 Batch 120/628] loss: 1.4147\n",
      "[Epoch 1 Batch 130/628] loss: 1.1757\n",
      "[Epoch 1 Batch 140/628] loss: 0.9799\n",
      "[Epoch 1 Batch 150/628] loss: 1.0729\n",
      "[Epoch 1 Batch 160/628] loss: 1.0795\n",
      "[Epoch 1 Batch 170/628] loss: 1.3938\n",
      "[Epoch 1 Batch 180/628] loss: 0.9923\n",
      "[Epoch 1 Batch 190/628] loss: 1.3547\n",
      "[Epoch 1 Batch 200/628] loss: 1.1607\n",
      "[Epoch 1 Batch 210/628] loss: 1.1368\n",
      "[Epoch 1 Batch 220/628] loss: 1.2473\n",
      "[Epoch 1 Batch 230/628] loss: 1.1958\n",
      "[Epoch 1 Batch 240/628] loss: 0.9265\n",
      "[Epoch 1 Batch 250/628] loss: 1.1500\n",
      "[Epoch 1 Batch 260/628] loss: 0.7542\n",
      "[Epoch 1 Batch 270/628] loss: 1.5164\n",
      "[Epoch 1 Batch 280/628] loss: 1.1098\n",
      "[Epoch 1 Batch 290/628] loss: 1.1418\n",
      "[Epoch 1 Batch 300/628] loss: 1.1494\n",
      "[Epoch 1 Batch 310/628] loss: 1.7314\n",
      "[Epoch 1 Batch 320/628] loss: 0.9016\n",
      "[Epoch 1 Batch 330/628] loss: 1.0422\n",
      "[Epoch 1 Batch 340/628] loss: 1.2305\n",
      "[Epoch 1 Batch 350/628] loss: 1.5580\n",
      "[Epoch 1 Batch 360/628] loss: 0.6982\n",
      "[Epoch 1 Batch 370/628] loss: 1.4630\n",
      "[Epoch 1 Batch 380/628] loss: 1.2127\n",
      "[Epoch 1 Batch 390/628] loss: 1.0205\n",
      "[Epoch 1 Batch 400/628] loss: 1.7365\n",
      "[Epoch 1 Batch 410/628] loss: 1.4578\n",
      "[Epoch 1 Batch 420/628] loss: 1.7272\n",
      "[Epoch 1 Batch 430/628] loss: 0.8208\n",
      "[Epoch 1 Batch 440/628] loss: 1.6877\n",
      "[Epoch 1 Batch 450/628] loss: 0.8132\n",
      "[Epoch 1 Batch 460/628] loss: 0.9885\n",
      "[Epoch 1 Batch 470/628] loss: 1.1336\n",
      "[Epoch 1 Batch 480/628] loss: 1.5022\n",
      "[Epoch 1 Batch 490/628] loss: 1.1350\n",
      "[Epoch 1 Batch 500/628] loss: 1.1438\n",
      "[Epoch 1 Batch 510/628] loss: 1.1775\n",
      "[Epoch 1 Batch 520/628] loss: 0.9624\n",
      "[Epoch 1 Batch 530/628] loss: 1.1226\n",
      "[Epoch 1 Batch 540/628] loss: 0.9989\n",
      "[Epoch 1 Batch 550/628] loss: 1.4295\n",
      "[Epoch 1 Batch 560/628] loss: 0.6554\n",
      "[Epoch 1 Batch 570/628] loss: 0.9323\n",
      "[Epoch 1 Batch 580/628] loss: 0.8478\n",
      "[Epoch 1 Batch 590/628] loss: 1.1454\n",
      "[Epoch 1 Batch 600/628] loss: 0.7774\n",
      "[Epoch 1 Batch 610/628] loss: 0.4096\n",
      "[Epoch 1 Batch 620/628] loss: 0.7809\n",
      "== Start Validation ==\n",
      "[Epoch 1] trn_loss: 1.1554, vld_loss: 1.2237, score: 0.8973, score_each: [0.8797, 0.9438, 0.8857]\n",
      "[Epoch 2 Batch 10/628] loss: 1.2288\n",
      "[Epoch 2 Batch 20/628] loss: 1.2366\n",
      "[Epoch 2 Batch 30/628] loss: 0.7051\n",
      "[Epoch 2 Batch 40/628] loss: 1.2552\n",
      "[Epoch 2 Batch 50/628] loss: 1.4535\n",
      "[Epoch 2 Batch 60/628] loss: 1.2432\n",
      "[Epoch 2 Batch 70/628] loss: 1.0280\n",
      "[Epoch 2 Batch 80/628] loss: 0.5121\n",
      "[Epoch 2 Batch 90/628] loss: 1.1518\n",
      "[Epoch 2 Batch 100/628] loss: 0.8770\n",
      "[Epoch 2 Batch 110/628] loss: 0.6756\n",
      "[Epoch 2 Batch 120/628] loss: 0.3208\n",
      "[Epoch 2 Batch 130/628] loss: 1.4369\n",
      "[Epoch 2 Batch 140/628] loss: 0.7838\n",
      "[Epoch 2 Batch 150/628] loss: 1.0803\n",
      "[Epoch 2 Batch 160/628] loss: 0.8470\n",
      "[Epoch 2 Batch 170/628] loss: 1.1697\n",
      "[Epoch 2 Batch 180/628] loss: 0.9911\n",
      "[Epoch 2 Batch 190/628] loss: 1.0582\n",
      "[Epoch 2 Batch 200/628] loss: 0.4391\n",
      "[Epoch 2 Batch 210/628] loss: 1.3375\n",
      "[Epoch 2 Batch 220/628] loss: 1.0161\n",
      "[Epoch 2 Batch 230/628] loss: 1.0582\n",
      "[Epoch 2 Batch 240/628] loss: 0.8675\n",
      "[Epoch 2 Batch 250/628] loss: 1.2825\n",
      "[Epoch 2 Batch 260/628] loss: 0.8313\n",
      "[Epoch 2 Batch 270/628] loss: 1.3572\n",
      "[Epoch 2 Batch 280/628] loss: 0.7698\n",
      "[Epoch 2 Batch 290/628] loss: 1.2430\n",
      "[Epoch 2 Batch 300/628] loss: 0.8926\n",
      "[Epoch 2 Batch 310/628] loss: 0.6754\n",
      "[Epoch 2 Batch 320/628] loss: 0.7116\n",
      "[Epoch 2 Batch 330/628] loss: 0.5759\n",
      "[Epoch 2 Batch 340/628] loss: 1.3093\n",
      "[Epoch 2 Batch 350/628] loss: 0.6915\n",
      "[Epoch 2 Batch 360/628] loss: 1.2432\n",
      "[Epoch 2 Batch 370/628] loss: 0.9820\n",
      "[Epoch 2 Batch 380/628] loss: 0.6369\n",
      "[Epoch 2 Batch 390/628] loss: 1.3171\n",
      "[Epoch 2 Batch 400/628] loss: 0.8414\n",
      "[Epoch 2 Batch 410/628] loss: 0.8873\n",
      "[Epoch 2 Batch 420/628] loss: 0.9016\n",
      "[Epoch 2 Batch 430/628] loss: 1.2340\n",
      "[Epoch 2 Batch 440/628] loss: 0.8569\n",
      "[Epoch 2 Batch 450/628] loss: 1.0541\n",
      "[Epoch 2 Batch 460/628] loss: 1.2247\n",
      "[Epoch 2 Batch 470/628] loss: 0.9937\n",
      "[Epoch 2 Batch 480/628] loss: 1.0324\n",
      "[Epoch 2 Batch 490/628] loss: 0.8364\n",
      "[Epoch 2 Batch 500/628] loss: 1.1140\n",
      "[Epoch 2 Batch 510/628] loss: 1.0237\n",
      "[Epoch 2 Batch 520/628] loss: 1.0603\n",
      "[Epoch 2 Batch 530/628] loss: 0.7003\n",
      "[Epoch 2 Batch 540/628] loss: 0.7729\n",
      "[Epoch 2 Batch 550/628] loss: 0.8640\n",
      "[Epoch 2 Batch 560/628] loss: 0.7442\n",
      "[Epoch 2 Batch 570/628] loss: 1.5299\n",
      "[Epoch 2 Batch 580/628] loss: 1.1240\n",
      "[Epoch 2 Batch 590/628] loss: 0.9334\n",
      "[Epoch 2 Batch 600/628] loss: 0.9759\n",
      "[Epoch 2 Batch 610/628] loss: 0.6782\n",
      "[Epoch 2 Batch 620/628] loss: 0.9496\n",
      "== Start Validation ==\n",
      "[Epoch 2] trn_loss: 0.9740, vld_loss: 1.2295, score: 0.9180, score_each: [0.8961, 0.9577, 0.9222]\n",
      "[Epoch 3 Batch 10/628] loss: 1.2816\n",
      "[Epoch 3 Batch 20/628] loss: 1.1559\n",
      "[Epoch 3 Batch 30/628] loss: 0.3732\n",
      "[Epoch 3 Batch 40/628] loss: 1.0382\n",
      "[Epoch 3 Batch 50/628] loss: 1.1544\n",
      "[Epoch 3 Batch 60/628] loss: 1.1309\n",
      "[Epoch 3 Batch 70/628] loss: 1.0228\n",
      "[Epoch 3 Batch 80/628] loss: 0.9145\n",
      "[Epoch 3 Batch 90/628] loss: 1.0645\n",
      "[Epoch 3 Batch 100/628] loss: 0.8038\n",
      "[Epoch 3 Batch 110/628] loss: 1.0180\n",
      "[Epoch 3 Batch 120/628] loss: 1.3194\n",
      "[Epoch 3 Batch 130/628] loss: 1.4629\n",
      "[Epoch 3 Batch 140/628] loss: 0.5475\n",
      "[Epoch 3 Batch 150/628] loss: 1.2257\n",
      "[Epoch 3 Batch 160/628] loss: 1.1296\n",
      "[Epoch 3 Batch 170/628] loss: 0.5604\n",
      "[Epoch 3 Batch 180/628] loss: 1.1776\n",
      "[Epoch 3 Batch 190/628] loss: 0.8746\n",
      "[Epoch 3 Batch 200/628] loss: 1.2029\n",
      "[Epoch 3 Batch 210/628] loss: 0.7897\n",
      "[Epoch 3 Batch 220/628] loss: 1.0891\n",
      "[Epoch 3 Batch 230/628] loss: 1.0204\n",
      "[Epoch 3 Batch 240/628] loss: 1.0252\n",
      "[Epoch 3 Batch 250/628] loss: 1.0131\n",
      "[Epoch 3 Batch 260/628] loss: 1.1770\n",
      "[Epoch 3 Batch 270/628] loss: 1.5817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3 Batch 280/628] loss: 0.8032\n",
      "[Epoch 3 Batch 290/628] loss: 1.3646\n",
      "[Epoch 3 Batch 300/628] loss: 1.0958\n",
      "[Epoch 3 Batch 310/628] loss: 0.6190\n",
      "[Epoch 3 Batch 320/628] loss: 0.9752\n",
      "[Epoch 3 Batch 330/628] loss: 0.8791\n",
      "[Epoch 3 Batch 340/628] loss: 1.2496\n",
      "[Epoch 3 Batch 350/628] loss: 1.6788\n",
      "[Epoch 3 Batch 360/628] loss: 0.9395\n",
      "[Epoch 3 Batch 370/628] loss: 1.2074\n",
      "[Epoch 3 Batch 380/628] loss: 0.9555\n",
      "[Epoch 3 Batch 390/628] loss: 1.4485\n",
      "[Epoch 3 Batch 400/628] loss: 0.9147\n",
      "[Epoch 3 Batch 410/628] loss: 1.1292\n",
      "[Epoch 3 Batch 420/628] loss: 1.1092\n",
      "[Epoch 3 Batch 430/628] loss: 1.1162\n",
      "[Epoch 3 Batch 440/628] loss: 1.4043\n",
      "[Epoch 3 Batch 450/628] loss: 0.6262\n",
      "[Epoch 3 Batch 460/628] loss: 0.4814\n",
      "[Epoch 3 Batch 470/628] loss: 1.6520\n",
      "[Epoch 3 Batch 480/628] loss: 1.1657\n",
      "[Epoch 3 Batch 490/628] loss: 0.6932\n",
      "[Epoch 3 Batch 500/628] loss: 1.4897\n",
      "[Epoch 3 Batch 510/628] loss: 0.8185\n",
      "[Epoch 3 Batch 520/628] loss: 0.8882\n",
      "[Epoch 3 Batch 530/628] loss: 1.0504\n",
      "[Epoch 3 Batch 540/628] loss: 0.8451\n",
      "[Epoch 3 Batch 550/628] loss: 0.6120\n",
      "[Epoch 3 Batch 560/628] loss: 1.0193\n",
      "[Epoch 3 Batch 570/628] loss: 0.6198\n",
      "[Epoch 3 Batch 580/628] loss: 0.9379\n",
      "[Epoch 3 Batch 590/628] loss: 1.4534\n",
      "[Epoch 3 Batch 600/628] loss: 0.9325\n",
      "[Epoch 3 Batch 610/628] loss: 1.1722\n",
      "[Epoch 3 Batch 620/628] loss: 1.2956\n",
      "== Start Validation ==\n",
      "[Epoch 3] trn_loss: 1.0461, vld_loss: 1.1424, score: 0.9348, score_each: [0.9157, 0.9610, 0.9468]\n",
      "[Epoch 4 Batch 10/628] loss: 0.6737\n",
      "[Epoch 4 Batch 20/628] loss: 1.4530\n",
      "[Epoch 4 Batch 30/628] loss: 0.6701\n",
      "[Epoch 4 Batch 40/628] loss: 0.9159\n",
      "[Epoch 4 Batch 50/628] loss: 1.2007\n",
      "[Epoch 4 Batch 60/628] loss: 0.7194\n",
      "[Epoch 4 Batch 70/628] loss: 0.7006\n",
      "[Epoch 4 Batch 80/628] loss: 0.8294\n",
      "[Epoch 4 Batch 90/628] loss: 0.8035\n",
      "[Epoch 4 Batch 100/628] loss: 0.5750\n",
      "[Epoch 4 Batch 110/628] loss: 1.1389\n",
      "[Epoch 4 Batch 120/628] loss: 0.7992\n",
      "[Epoch 4 Batch 130/628] loss: 1.3889\n",
      "[Epoch 4 Batch 140/628] loss: 1.5621\n",
      "[Epoch 4 Batch 150/628] loss: 1.8147\n",
      "[Epoch 4 Batch 160/628] loss: 1.2277\n",
      "[Epoch 4 Batch 170/628] loss: 1.2561\n",
      "[Epoch 4 Batch 180/628] loss: 1.3467\n",
      "[Epoch 4 Batch 190/628] loss: 1.0712\n",
      "[Epoch 4 Batch 200/628] loss: 0.7067\n",
      "[Epoch 4 Batch 210/628] loss: 0.9809\n",
      "[Epoch 4 Batch 220/628] loss: 1.1307\n",
      "[Epoch 4 Batch 230/628] loss: 0.4296\n",
      "[Epoch 4 Batch 240/628] loss: 0.5170\n",
      "[Epoch 4 Batch 250/628] loss: 1.1590\n",
      "[Epoch 4 Batch 260/628] loss: 0.9115\n",
      "[Epoch 4 Batch 270/628] loss: 1.7376\n",
      "[Epoch 4 Batch 280/628] loss: 0.8356\n",
      "[Epoch 4 Batch 290/628] loss: 1.0523\n",
      "[Epoch 4 Batch 300/628] loss: 1.0048\n",
      "[Epoch 4 Batch 310/628] loss: 1.1220\n",
      "[Epoch 4 Batch 320/628] loss: 1.0725\n",
      "[Epoch 4 Batch 330/628] loss: 0.6245\n",
      "[Epoch 4 Batch 340/628] loss: 1.5427\n",
      "[Epoch 4 Batch 350/628] loss: 1.2245\n",
      "[Epoch 4 Batch 360/628] loss: 0.9870\n",
      "[Epoch 4 Batch 370/628] loss: 1.3414\n",
      "[Epoch 4 Batch 380/628] loss: 1.1910\n",
      "[Epoch 4 Batch 390/628] loss: 0.3654\n",
      "[Epoch 4 Batch 400/628] loss: 0.5760\n",
      "[Epoch 4 Batch 410/628] loss: 0.9769\n",
      "[Epoch 4 Batch 420/628] loss: 0.9404\n",
      "[Epoch 4 Batch 430/628] loss: 1.3749\n",
      "[Epoch 4 Batch 440/628] loss: 0.4190\n",
      "[Epoch 4 Batch 450/628] loss: 0.6254\n",
      "[Epoch 4 Batch 460/628] loss: 0.6947\n",
      "[Epoch 4 Batch 470/628] loss: 0.6069\n",
      "[Epoch 4 Batch 480/628] loss: 0.9056\n",
      "[Epoch 4 Batch 490/628] loss: 0.9659\n",
      "[Epoch 4 Batch 500/628] loss: 0.7380\n",
      "[Epoch 4 Batch 510/628] loss: 1.1998\n",
      "[Epoch 4 Batch 520/628] loss: 0.9345\n",
      "[Epoch 4 Batch 530/628] loss: 0.7216\n",
      "[Epoch 4 Batch 540/628] loss: 1.2507\n",
      "[Epoch 4 Batch 550/628] loss: 0.8932\n",
      "[Epoch 4 Batch 560/628] loss: 0.8180\n",
      "[Epoch 4 Batch 570/628] loss: 0.9920\n",
      "[Epoch 4 Batch 580/628] loss: 0.8656\n",
      "[Epoch 4 Batch 590/628] loss: 1.4435\n",
      "[Epoch 4 Batch 600/628] loss: 0.8313\n",
      "[Epoch 4 Batch 610/628] loss: 0.8674\n",
      "[Epoch 4 Batch 620/628] loss: 0.7485\n",
      "== Start Validation ==\n",
      "[Epoch 4] trn_loss: 0.9749, vld_loss: 1.2042, score: 0.9429, score_each: [0.9191, 0.9711, 0.9622]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    '''\n",
    "    CutMix Helper function.\n",
    "    Retrieved from https://github.com/clovaai/CutMix-PyTorch/blob/master/train.py\n",
    "    '''\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    # 폭과 높이는 주어진 이미지의 폭과 높이의 beta distribution에서 뽑은 lambda로 얻는다\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    \n",
    "    # patch size 의 w, h 는 original image 의 w,h 에 np.sqrt(1-lambda) 를 곱해준 값입니다.\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # patch의 중심점은 uniform하게 뽑힘\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "best_score = -1\n",
    "log_interval = 10\n",
    "training_stats = []\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch_id in range(num_epochs):\n",
    "\n",
    "    ################################################################################\n",
    "    # ==> Training phase\n",
    "    ################################################################################    \n",
    "    trn_loss = []\n",
    "    model.train()\n",
    "    \n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_id, (inputs, targets) in enumerate((trn_loader)):\n",
    "        inputs = inputs.cuda()\n",
    "        targets = targets.cuda()\n",
    "        targets_gra = targets[:, 0]\n",
    "        targets_vow = targets[:, 1]\n",
    "        targets_con = targets[:, 2]\n",
    "                    \n",
    "        # 50%의 확률로 원본 데이터 그대로 사용    \n",
    "        if np.random.rand() < 0.5:\n",
    "            logits = model(inputs)\n",
    "            grapheme = logits[:, :168]\n",
    "            vowel = logits[:, 168:179]\n",
    "            cons = logits[:, 179:]\n",
    "            \n",
    "            loss1 = loss_fn(grapheme, targets_gra)\n",
    "            loss2 = loss_fn(vowel, targets_vow)\n",
    "            loss3 = loss_fn(cons, targets_con) \n",
    "        \n",
    "        else:\n",
    "            \n",
    "            lam = np.random.beta(1.0, 1.0) \n",
    "            rand_index = torch.randperm(inputs.size()[0])\n",
    "            shuffled_targets_gra = targets_gra[rand_index]\n",
    "            shuffled_targets_vow = targets_vow[rand_index]\n",
    "            shuffled_targets_con = targets_con[rand_index]\n",
    "            \n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)\n",
    "            inputs[:, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "            # 픽셀 비율과 정확히 일치하도록 lambda 파라메터 조정  \n",
    "            lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (inputs.size()[-1] * inputs.size()[-2]))\n",
    "            \n",
    "            logits = model(inputs)\n",
    "            grapheme = logits[:,:168]\n",
    "            vowel = logits[:, 168:179]\n",
    "            cons = logits[:, 179:]\n",
    "            \n",
    "            loss1 = loss_fn(grapheme, targets_gra) * lam + loss_fn(grapheme, shuffled_targets_gra) * (1. - lam)\n",
    "            loss2 = loss_fn(vowel, targets_vow) * lam + loss_fn(vowel, shuffled_targets_vow) * (1. - lam)\n",
    "            loss3 = loss_fn(cons, targets_con) * lam + loss_fn(cons, shuffled_targets_con) * (1. - lam)\n",
    "        \n",
    "        loss = 0.5 * loss1 + 0.25 * loss2 + 0.25 * loss3    \n",
    "        trn_loss.append(loss.item())\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Printing vital information\n",
    "        if (batch_id + 1) % (log_interval) == 0:\n",
    "            s = f'[Epoch {epoch_id} Batch {batch_id+1}/{len(trn_loader)}] ' \\\n",
    "            f'loss: {running_loss / log_interval:.4f}'\n",
    "            print(s)\n",
    "            running_loss = 0\n",
    "\n",
    "    # Measure how long this epoch took.\n",
    "    trn_time = format_time(time.time() - t0)        \n",
    "\n",
    "    ################################################################################\n",
    "    # ==> Validation phase\n",
    "    ################################################################################\n",
    "    val_loss = []\n",
    "    val_true = []\n",
    "    val_pred = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in vld_loader:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            logits = model(inputs)\n",
    "            grapheme = logits[:,:168]\n",
    "            vowel = logits[:, 168:179]\n",
    "            cons = logits[:, 179:]\n",
    "\n",
    "            loss= 0.5* loss_fn(grapheme, targets[:,0]) + 0.25*loss_fn(vowel, targets[:,1]) + \\\n",
    "            0.25*loss_fn(vowel, targets[:,2])\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "\n",
    "            grapheme = grapheme.cpu().argmax(dim=1).data.numpy()\n",
    "            vowel = vowel.cpu().argmax(dim=1).data.numpy()\n",
    "            cons = cons.cpu().argmax(dim=1).data.numpy()\n",
    "\n",
    "            val_true.append(targets.cpu().numpy())\n",
    "            val_pred.append(np.stack([grapheme, vowel, cons], axis=1))                \n",
    "\n",
    "    val_true = np.concatenate(val_true)\n",
    "    val_pred = np.concatenate(val_pred)\n",
    "    val_loss = np.mean(val_loss)\n",
    "    trn_loss = np.mean(trn_loss)\n",
    "\n",
    "    score_g = recall_score(val_true[:,0], val_pred[:,0], average='macro')\n",
    "    score_v = recall_score(val_true[:,1], val_pred[:,1], average='macro')\n",
    "    score_c = recall_score(val_true[:,2], val_pred[:,2], average='macro')\n",
    "    final_score = np.average([score_g, score_v, score_c], weights=[2,1,1])\n",
    "   \n",
    "    # Printing vital information\n",
    "    print('== Start Validation ==')\n",
    "    s = f'[Epoch {epoch_id}] ' \\\n",
    "    f'trn_loss: {trn_loss:.4f}, vld_loss: {val_loss:.4f}, score: {final_score:.4f}, ' \\\n",
    "    f'score_each: [{score_g:.4f}, {score_v:.4f}, {score_c:.4f}]'          \n",
    "    print(s)\n",
    "\n",
    "    ################################################################################\n",
    "    # ==> Save checkpoint and training stats\n",
    "    ################################################################################        \n",
    "    if final_score > best_score:\n",
    "        best_score = final_score\n",
    "        state_dict = model.cpu().state_dict()\n",
    "        model = model.cuda()\n",
    "        torch.save(state_dict, 'model.pt')\n",
    "        \n",
    "    # Record all statistics from this epoch\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_id + 1,\n",
    "            'trn_loss': trn_loss,\n",
    "            'trn_time': trn_time,            \n",
    "            'val_loss': val_loss,\n",
    "            'score': final_score,\n",
    "            'score_g': score_g,\n",
    "            'score_v': score_v,\n",
    "            'score_c': score_c            \n",
    "        }\n",
    "    )            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Check training results\n",
    "\n",
    "훈련 결과를 간단히 살펴봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>score_c</th>\n",
       "      <th>score_g</th>\n",
       "      <th>score_v</th>\n",
       "      <th>trn_loss</th>\n",
       "      <th>trn_time</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8557</td>\n",
       "      <td>0.8818</td>\n",
       "      <td>0.8070</td>\n",
       "      <td>0.9268</td>\n",
       "      <td>1.5552</td>\n",
       "      <td>0:05:39</td>\n",
       "      <td>1.3846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8973</td>\n",
       "      <td>0.8857</td>\n",
       "      <td>0.8797</td>\n",
       "      <td>0.9438</td>\n",
       "      <td>1.1554</td>\n",
       "      <td>0:05:28</td>\n",
       "      <td>1.2237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9180</td>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.8961</td>\n",
       "      <td>0.9577</td>\n",
       "      <td>0.9740</td>\n",
       "      <td>0:05:34</td>\n",
       "      <td>1.2295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9348</td>\n",
       "      <td>0.9468</td>\n",
       "      <td>0.9157</td>\n",
       "      <td>0.9610</td>\n",
       "      <td>1.0461</td>\n",
       "      <td>0:05:34</td>\n",
       "      <td>1.1424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9429</td>\n",
       "      <td>0.9622</td>\n",
       "      <td>0.9191</td>\n",
       "      <td>0.9711</td>\n",
       "      <td>0.9749</td>\n",
       "      <td>0:05:36</td>\n",
       "      <td>1.2042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        score  score_c  score_g  score_v  trn_loss trn_time  val_loss\n",
       "epoch                                                                \n",
       "1      0.8557   0.8818   0.8070   0.9268    1.5552  0:05:39    1.3846\n",
       "2      0.8973   0.8857   0.8797   0.9438    1.1554  0:05:28    1.2237\n",
       "3      0.9180   0.9222   0.8961   0.9577    0.9740  0:05:34    1.2295\n",
       "4      0.9348   0.9468   0.9157   0.9610    1.0461  0:05:34    1.1424\n",
       "5      0.9429   0.9622   0.9191   0.9711    0.9749  0:05:36    1.2042"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('precision', 4)\n",
    "\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "display(df_stats)\n",
    "\n",
    "#model.load_state_dict(torch.load('./model.pt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
